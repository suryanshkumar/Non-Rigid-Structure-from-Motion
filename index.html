<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
  body {
    font-family: "Titillium Web", "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight: 300;
    font-size: 17px;
    margin-left: auto;
    margin-right: auto;
    width: 980px;
  }

  h1 {
    font-weight: 300;
    line-height: 1.15em;
  }

  h2 {
    font-size: 1.75em;
  }

  a:link,
  a:visited {
    color: #1367a7;
    text-decoration: none;
  }

  a:hover {
    color: #208799;
  }

  h1,
  h2,
  h3 {
    text-align: center;
  }

  h1 {
    font-size: 40px;
    font-weight: 500;
  }

  h2 {
    font-weight: 400;
    margin: 16px 0px 4px 0px;
  }

  .paper-title {
    padding: 16px 0px 16px 0px;
  }

  section {
    margin: 32px 0px 32px 0px;
    text-align: justify;
    clear: both;
  }

  .col-5 {
    width: 20%;
    float: left;
  }

  .col-4 {
    width: 25%;
    float: left;
  }

  .col-2 {
    width: 50%;
    float: left;
  }

  .row,
  .author-row,
  .affil-row {
    overflow: auto;
  }

  .author-row,
  .affil-row {
    font-size: 20px;
  }

  .row {
    margin: 16px 0px 16px 0px;
  }

  .authors {
    font-size: 18px;
  }

  .affil-row {
    margin-top: 16px;
  }

  .teaser {
    max-width: 100%;
  }

  .text-center {
    text-align: center;
  }

  .screenshot {
    width: 256px;
    border: 1px solid #ddd;
  }

  .screenshot-el {
    margin-bottom: 16px;
  }

  hr {
    height: 1px;
    border: 0;
    border-top: 1px solid #ddd;
    margin: 0;
  }

  .material-icons {
    vertical-align: -6px;
  }

  p {
    line-height: 1.25em;
  }

  .caption {
    font-size: 16px;
    /*font-style: italic;*/
    color: #666;
    text-align: center;
    margin-top: 8px;
    margin-bottom: 8px;
  }

  video {
    display: block;
    margin: auto;
  }

  figure {
    display: block;
    margin: auto;
    margin-top: 10px;
    margin-bottom: 10px;
  }

  #bibtex pre {
    font-size: 14px;
    background-color: #eee;
    padding: 16px;
  }

  .blue {
    color: #2c82c9;
    font-weight: bold;
  }

  .orange {
    color: #d35400;
    font-weight: bold;
  }

  .flex-row {
    display: flex;
    flex-flow: row wrap;
    justify-content: space-around;
    padding: 0;
    margin: 0;
    list-style: none;
  }

  .paper-btn {
    position: relative;
    text-align: center;

    display: inline-block;
    margin: 8px;
    padding: 8px 8px;

    border-width: 0;
    outline: none;
    border-radius: 2px;

    background-color: #1367a7;
    color: #ecf0f1 !important;
    font-size: 20px;
    width: 100px;
    font-weight: 600;
  }

  .paper-btn-parent {
    display: flex;
    justify-content: center;
    margin: 16px 0px;
  }

  .paper-btn:hover {
    opacity: 0.85;
  }

  .container {
    margin-left: auto;
    margin-right: auto;
    padding-left: 16px;
    padding-right: 16px;
  }

  .venue {
    color: #1367a7;
  }
</style>

<!-- End : Google Analytics Code -->
<script type="text/javascript" src="../js/hidebib.js"></script>
<link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic'
  rel='stylesheet' type='text/css'>

<head>
  <title>Non-Rigid Structure from Motion</title>
  <meta property="og:description" content="Non-Rigid Structure from Motion" />
  <link href="https://fonts.googleapis.com/css2?family=Material+Icons" rel="stylesheet">

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:creator" content="">
  <meta name="twitter:title" content="Non-Rigid Structure from Motion">
  <meta name="twitter:description" content="">
  <meta name="twitter:image" content="">

</head>

<body>
  <div class="container">
    <div class="paper-title">
      <h1>Non-Rigid Structure from Motion</h1>
    </div>

    <div id="authors">
      <div class="author-row">
        <div align="center"><a href="https://suryanshkumar.github.io/">Suryansh Kumar</a>, ETH Zurich</div>
      </div>
    </div>

    <section id="teaser">
      <a href="./Figures/NRSFM.png">
        <img width="100%" src="./Figures/NRSFM.png">
      </a>
    </section>


    <section id="abstract" />
    <h2>Abstract</h2>
    <hr>
    <div class="flex-row">
      <div style="width: 60%">
        <p>The problem of recovering the 3D shape of a non-rigidly deforming object from its image feature
          correspondences across multiple frames is widely known as Non-Rigid Structure from Motion (NRSfM). It is a
          well-defined classical problem whose solution can assist several industrial applications in virtual reality,
          medical surgery, movies, etc. However, the task is challenging due to the inherent unconstrained nature of the
          problem itself, as many 3D varying configurations can have similar image projections. To date, no algorithm
          can solve NRSfM for all kinds of conceivable motion. Consequently, additional constraints, priors, and
          assumptions are often employed to solve NRSfM. Our work takes on this challenging problem and proposes
          algorithms that have set a new performance benchmark to solve NRSfM. Our solutions discuss the classical work
          in NRSfM and suggest necessary elementary modifications to it. The foundation of our contributions surpasses
          the traditional single object NRSFM and, for the first time, provides an effective formulation to realize
          multi-body NRSfM. Further, most NRSfM factorization methods can effectively handle only sparse feature
          correspondences. Later, sparse 3d points are used to approximate the object's dense shape via the organization
          of 3d points, planes, or other elementary geometric primitive. Nevertheless, sparse representation provides
          incomplete information about the object's global shape. On the contrary, our proposed methods can directly
          solve dense NRSfM showing state-of-the-art accuracy.
        </p>
      </div>
      <div style="width: 40%">
        <figure style="padding-left: 24px; margin-bottom: 0">
          <img width="100%" src="./Figures/nrsfm_setup.png">
          <p class="caption">
            A visual illustration of basic pipeline setup for NRSfM factorization. The above dataset is taken from
            walking sequence introduced by Torresani et al. T-PAMI, 2008.
          </p>
        </figure>
      </div>
    </div>
    <p>

      For <b>dense NRSfM</b>, we show that we can recover deforming shape 3d with favorable accuracy using just matrix
      factorization approach. However, a carefully modeling using local linear subspace structure can further enchance 
      the dense NRSfM  performance accuracy. The figure below show the visualization of such a linear subspace modeling 
      using grassmannian representation.

    <figure style="margin-top: 20px; margin-bottom: 20px;">
      <img width="100%" src="Figures/dense_modeling.png">
      <p class="caption">
        We represent shape as a union of low-dimensional linear subspace.
      <p class="caption">
      </p>
    </figure>
    </section>

    <section id="results">
      <h2>Qualitative Results</h2>
      <hr>
      <figure style="width: 100%;">
        <a href="Figures/nrsfm_challenge_results.png">
          <img width="100%" src="Figures/nrsfm_challenge_results.png">
        </a>
        <p class="caption" style="margin-bottom: 24px;">
          <b>Sparse NRSfM:</b> Qualitative Results on CVPR NRSfM Challenge 2017 Dataset (Jensen et al. IJCV 2021).
        </p>
      </figure><br/><br/>

      <figure style="width: 100%;">
        <a href="Figures/multibody_results.png">
          <img width="100%" src="Figures/multibody_results.png">
        </a>
        <p class="caption">
          <b>Multi-body Sparse NRSfM:</b> Qualitative Results on Motion Capture Dataset. We synthesized multi-body
          dataset using Akther et al. NIPS 2009 and Torresani et al. TPAMI 2008 dataset sequence.
        </p>
      </figure><br/><br/>

      <figure style="width: 100%;">
        <a href="Figures/dense_nrsfm_results.png">
          <img width="100%" src="Figures/dense_nrsfm_results.png">
        </a>
        <p class="caption">
          <b>Dense NRSfM:</b> Qualitative Results on Garg et al. CVPR 2013, Varol et al. CVPR 2012 dataset.
        </p>
      </figure>
    </section><br/>

    <section id="paper">
      <h2>Published Work and Other Useful Links</h2>
      <hr>
      <div class="flex-row">
        <div style="width: 100%">

          [1]. <a href="https://arxiv.org/abs/2207.06262" style="color: rgb(92, 17, 17)">Organic Priors in Non-Rigid Structure from Motion</a>,
          <b> ECCV 2022.</b><br />

          [2]. <a href="https://ieeexplore.ieee.org/document/8910408" style="color: rgb(92, 17, 17)">Superpixel Soup: Monocular Dense 3D Reconstruction of a Complex Dynamic Scene</a>, 
          <b> IEEE T-PAMI 2021.</b><br/>

          [3]. <a href="https://ieeexplore.ieee.org/document/9093514" style="color: rgb(92, 17, 17)">Non-Rigid Structure from Motion: Prior-Free Factorization Method Revisited</a>, 
          <b> IEEE/CVF WACV 2020.</b><br/>

          [4]. <a href="https://ieeexplore.ieee.org/document/8953811" style="color: rgb(92, 17, 17)">Jumping manifolds: Geometry aware dense non-rigid structure from motion</a>, 
          <b> IEEE/CVF CVPR 2019.</b><br/>

          [5]. <a href="https://ieeexplore.ieee.org/document/8578132" style="color: rgb(92, 17, 17)">Scalable dense non-rigid structure-from-motion: A grassmannian perspective</a>, 
          <b> IEEE/CVF CVPR 2018.</b><br/>

          [6]. <a href="https://ieeexplore.ieee.org/document/8237760" style="color: rgb(92, 17, 17)">Monocular dense 3d reconstruction of a complex dynamic scene from two perspective frames</a>, 
          <b> IEEE/CVF ICCV 2017.</b><br/>

          [7]. <a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320317302029?via%3Dihub" style="color: rgb(92, 17, 17)">Spatial-Temporal Union of Subspaces for Multi body Non-rigid Structure from Motion</a>, 
          <b> Elsevier Pattern Recognition 2017.</b><br/>

          [8]. <a href="https://ieeexplore.ieee.org/document/7785087" style="color: rgb(92, 17, 17)">Multi body Non-rigid Structure from Motion</a>,
          <b> IEEE 3DV 2016.</b><br/>
          <br/><br/>

          <div align="center">
            <span class="material-icons"> description </span><a href="https://arxiv.org/a/kumar_s_12.html"> arXiv page </a>
            &nbsp;&nbsp; <span class="material-icons"> insert_comment </span><a href="Bib/bibtex.txt"> BibTeX</a>
            &nbsp;&nbsp; <span class="material-icons"> integration_instructions </span><a href="https://github.com/suryanshkumar"> Dataset</a>
            &nbsp;&nbsp; <span class="material-icons"> integration_instructions </span><a href="https://github.com/suryanshkumar"> Code</a>
            &nbsp;&nbsp; <span class="material-icons"> videocam </span><a href="https://www.youtube.com/channel/UCJiGIKtRjtPVl2gct9-ojag"> Video</a>
          </div>
        </div>
      </div>
    </section><br/>

    <section id="bibtex">
      <h2>Project Accomplishment</h2>
      <hr>
      <pre><code>
		<li>Recipient of Best Algorithm Award from Disney Research at NRSFM challenge CVPR 2017, Hawaii USA.</li>
      		<li>Nominated for J.G Crawford Prize for Best Doctoral Thesis 2019, ANU Canberra.</li>
      		<li>Recipient of HDR Merit Scholarship, funded in part by Australian Research Council.</li>
      		<li>Recipient of Vice-Chancellor Grant for CVPR 2018 Conference, Salt Lake City, Utah USA.</li>
	</code></pre>
    </section>

    <section id="acknowledgements">
       	<!--Authors-->
         <table align=center style="width: 100%;">
           <center>
            <h2>Authors and Acknowledgements</h2>
            <hr>
           </center>

            <tr align="center">
			        <td>
				      <div class="author_image"><img style="height:150px" src="Figures/colab/suryansh.JPG"><a href="https://suryanshkumar.github.io/">Suryansh Kumar</a></div>
			        </td>

			        <td>
				      <div class="author_image"><img style="height:150px" src="Figures/colab/yuchaodai.jpeg"><a href="https://scholar.google.com/citations?user=fddAbqsAAAAJ&hl=en">Yuchao Dai</a></div>
			        </td>

			        <td>
				      <div class="author_image"><img style="height:150px" src="Figures/colab/hongdongli.png"><a href="https://scholar.google.com/citations?user=Mq89JAcAAAAJ&hl=en">Hongdong Li</a></div>
			        </td>

			        <td>
				      <div class="author_image"><img style="height:150px" src="Figures/colab/luc.png"><a href="https://scholar.google.com/citations?user=TwMib_QAAAAJ&hl=en">Luc Van Gool</a></div>
              </td>

              <td>
				      <div class="author_image"><img style="height:150px" src="Figures/colab/arc.jpg"><a>ARC, Australia</a></div>
			        </td>

              <td>
				      <div class="author_image"><img style="height:150px" src="Figures/colab/cvl.jpg"><a href="https://icu.ee.ethz.ch/">CVL, ETH Zurich</a></div>
			        </td>
            </tr>
          </table>
    </section>
  </div>
</body>

</html>